
Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.7.4 => python/3.6.3

starting org.apache.spark.deploy.master.Master, logging to /home/p/primath/maxzhang/.spark/2.4.4/log/spark-7615933-org.apache.spark.deploy.master.Master-1-nia0739.scinet.local.out
Master URL = spark://nia0739:7077
Number of Workers = 3
https://repos.spark-packages.org added as a remote repository with the name: repo-1
Ivy Default Cache set to: /home/p/primath/maxzhang/.ivy2/cache
The jars for the packages stored in: /home/p/primath/maxzhang/.ivy2/jars
:: loading settings :: url = jar:file:/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/spark/2.4.4/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-58a383e2-7ddb-42d6-a662-5808ce7c3fa6;1.0
	confs: [default]
	found graphframes#graphframes;0.6.0-spark2.3-s_2.11 in local-m2-cache
downloading file:/home/p/primath/maxzhang/.m2/repository/graphframes/graphframes/0.6.0-spark2.3-s_2.11/graphframes-0.6.0-spark2.3-s_2.11.jar ...
	[SUCCESSFUL ] graphframes#graphframes;0.6.0-spark2.3-s_2.11!graphframes.jar (5ms)
:: resolution report :: resolve 769420ms :: artifacts dl 7ms
	:: modules in use:
	graphframes#graphframes;0.6.0-spark2.3-s_2.11 from local-m2-cache in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   1   |   1   |   0   |   0   ||   1   |   1   |
	---------------------------------------------------------------------

:: problems summary ::
:::: ERRORS
	Server access error at url https://repo1.maven.org/maven2/graphframes/graphframes/0.6.0-spark2.3-s_2.11/graphframes-0.6.0-spark2.3-s_2.11.pom (java.net.ConnectException: Connection timed out (Connection timed out))

	Server access error at url https://repo1.maven.org/maven2/graphframes/graphframes/0.6.0-spark2.3-s_2.11/graphframes-0.6.0-spark2.3-s_2.11.jar (java.net.ConnectException: Connection timed out (Connection timed out))

	Server access error at url https://dl.bintray.com/spark-packages/maven/graphframes/graphframes/0.6.0-spark2.3-s_2.11/graphframes-0.6.0-spark2.3-s_2.11.pom (java.net.ConnectException: Connection timed out (Connection timed out))

	Server access error at url https://dl.bintray.com/spark-packages/maven/graphframes/graphframes/0.6.0-spark2.3-s_2.11/graphframes-0.6.0-spark2.3-s_2.11.jar (java.net.ConnectException: Connection timed out (Connection timed out))

	Server access error at url https://repos.spark-packages.org/graphframes/graphframes/0.6.0-spark2.3-s_2.11/graphframes-0.6.0-spark2.3-s_2.11.pom (java.net.ConnectException: Connection timed out (Connection timed out))

	Server access error at url https://repos.spark-packages.org/graphframes/graphframes/0.6.0-spark2.3-s_2.11/graphframes-0.6.0-spark2.3-s_2.11.jar (java.net.ConnectException: Connection timed out (Connection timed out))


:: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS
:: retrieving :: org.apache.spark#spark-submit-parent-58a383e2-7ddb-42d6-a662-5808ce7c3fa6
	confs: [default]
	1 artifacts copied, 0 already retrieved (343kB/21ms)
22/06/28 15:57:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.6/site-packages/matplotlib/font_manager.py:232: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.
  'Matplotlib is building the font cache using fc-list. '
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/06/28 15:59:48 INFO SparkContext: Running Spark version 2.4.4
22/06/28 15:59:48 INFO SparkContext: Submitted application: covid19vaccine_twitter_replyto_net_feb2021
22/06/28 15:59:48 INFO SecurityManager: Changing view acls to: maxzhang
22/06/28 15:59:48 INFO SecurityManager: Changing modify acls to: maxzhang
22/06/28 15:59:48 INFO SecurityManager: Changing view acls groups to: 
22/06/28 15:59:48 INFO SecurityManager: Changing modify acls groups to: 
22/06/28 15:59:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(maxzhang); groups with view permissions: Set(); users  with modify permissions: Set(maxzhang); groups with modify permissions: Set()
22/06/28 15:59:48 INFO Utils: Successfully started service 'sparkDriver' on port 46808.
22/06/28 15:59:48 INFO SparkEnv: Registering MapOutputTracker
22/06/28 15:59:48 INFO SparkEnv: Registering BlockManagerMaster
22/06/28 15:59:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/06/28 15:59:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/06/28 15:59:48 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3a0f2218-c802-4922-af28-6cd399d56ec0
22/06/28 15:59:48 INFO MemoryStore: MemoryStore started with capacity 53.2 GB
22/06/28 15:59:48 INFO SparkEnv: Registering OutputCommitCoordinator
22/06/28 15:59:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/06/28 15:59:48 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://nia0739:4040
22/06/28 15:59:48 INFO SparkContext: Added JAR file:///home/p/primath/maxzhang/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar at spark://nia0739:46808/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar with timestamp 1656446388786
22/06/28 15:59:48 INFO SparkContext: Added file file:///home/p/primath/maxzhang/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar at spark://nia0739:46808/files/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar with timestamp 1656446388802
22/06/28 15:59:48 INFO Utils: Copying /home/p/primath/maxzhang/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar to /tmp/spark-9d681c9d-174f-46d3-a1fb-f95d1e466b6f/userFiles-1e673d27-fe2c-4bb0-a70c-0f4e0807e5c4/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar
22/06/28 15:59:48 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://nia0739:7077...
22/06/28 15:59:48 INFO TransportClientFactory: Successfully created connection to nia0739/10.20.11.19:7077 after 28 ms (0 ms spent in bootstraps)
22/06/28 15:59:49 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20220628155949-0000
22/06/28 15:59:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40674.
22/06/28 15:59:49 INFO NettyBlockTransferService: Server created on nia0739:40674
22/06/28 15:59:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/06/28 15:59:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20220628155949-0000/0 on worker-20220628154453-10.20.11.22-42845 (10.20.11.22:42845) with 5 core(s)
22/06/28 15:59:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20220628155949-0000/0 on hostPort 10.20.11.22:42845 with 5 core(s), 16.0 GB RAM
22/06/28 15:59:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20220628155949-0000/1 on worker-20220628154453-10.20.11.21-35097 (10.20.11.21:35097) with 5 core(s)
22/06/28 15:59:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20220628155949-0000/1 on hostPort 10.20.11.21:35097 with 5 core(s), 16.0 GB RAM
22/06/28 15:59:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20220628155949-0000/2 on worker-20220628154453-10.20.11.20-40819 (10.20.11.20:40819) with 5 core(s)
22/06/28 15:59:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20220628155949-0000/2 on hostPort 10.20.11.20:40819 with 5 core(s), 16.0 GB RAM
22/06/28 15:59:49 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20220628155949-0000/3 on worker-20220628154453-10.20.11.20-34316 (10.20.11.20:34316) with 5 core(s)
22/06/28 15:59:49 INFO StandaloneSchedulerBackend: Granted executor ID app-20220628155949-0000/3 on hostPort 10.20.11.20:34316 with 5 core(s), 16.0 GB RAM
22/06/28 15:59:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, nia0739, 40674, None)
22/06/28 15:59:49 INFO BlockManagerMasterEndpoint: Registering block manager nia0739:40674 with 53.2 GB RAM, BlockManagerId(driver, nia0739, 40674, None)
22/06/28 15:59:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, nia0739, 40674, None)
22/06/28 15:59:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, nia0739, 40674, None)
22/06/28 15:59:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20220628155949-0000/2 is now RUNNING
22/06/28 15:59:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20220628155949-0000/0 is now RUNNING
22/06/28 15:59:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20220628155949-0000/1 is now RUNNING
22/06/28 15:59:49 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20220628155949-0000/3 is now RUNNING
22/06/28 15:59:49 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
22/06/28 15:59:50 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/gpfs/fs0/scratch/p/primath/maxzhang/distributed-network-layout/spark-warehouse').
22/06/28 15:59:50 INFO SharedState: Warehouse path is 'file:/gpfs/fs0/scratch/p/primath/maxzhang/distributed-network-layout/spark-warehouse'.
22/06/28 15:59:50 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
Successfully created the directory sampleOutput1checkpoint 
Num of nodes: 25944
Num of edges: 18065
Traceback (most recent call last):
  File "/gpfs/fs0/scratch/p/primath/maxzhang/distributed-network-layout/DistributedLayoutAlgorithm.py", line 244, in <module>
    graphs[i] = GraphFrame(nodesCheckpoint,edgesCheckpoint)
  File "/home/p/primath/maxzhang/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar/graphframes/graphframe.py", line 65, in __init__
  File "/home/p/primath/maxzhang/.ivy2/jars/graphframes_graphframes-0.6.0-spark2.3-s_2.11.jar/graphframes/graphframe.py", line 38, in _java_api
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/spark/2.4.4/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py", line 1257, in __call__
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/spark/2.4.4/python/lib/pyspark.zip/pyspark/sql/utils.py", line 63, in deco
  File "/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/spark/2.4.4/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py", line 328, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o77.newInstance.
: java.lang.NoClassDefFoundError: com/typesafe/scalalogging/slf4j/LazyLogging
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:763)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:468)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:763)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:468)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at org.graphframes.GraphFramePythonAPI.<init>(GraphFramePythonAPI.scala:12)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at java.lang.Class.newInstance(Class.java:442)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.ClassNotFoundException: com.typesafe.scalalogging.slf4j.LazyLogging
	at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	... 39 more

srun: error: nia0739: task 0: Exited with exit code 1
srun: launch/slurm: _step_signal: Terminating StepId=7615933.0
srun: forcing job termination
srun: Job step aborted: Waiting up to 62 seconds for job step to finish.
srun: error: nia0740: tasks 0-1: Killed
srun: launch/slurm: _step_signal: Terminating StepId=7615933.1
stopping org.apache.spark.deploy.master.Master

scontrol show jobid 7615933
JobId=7615933 JobName=DistributedLayoutAlgorithm
   UserId=maxzhang(3119754) GroupId=primath(6038442) MCS_label=N/A
   Priority=2380384 Nice=0 Account=rrg-primath QOS=normal
   JobState=COMPLETED Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:15:47 TimeLimit=1-00:00:00 TimeMin=N/A
   SubmitTime=2022-06-28T15:43:52 EligibleTime=2022-06-28T15:43:52
   AccrueTime=2022-06-28T15:43:52
   StartTime=2022-06-28T15:43:53 EndTime=2022-06-28T15:59:40 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2022-06-28T15:43:53 Scheduler=Main
   Partition=compute AllocNode:Sid=nia-login03:61617
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=nia[0739-0742]
   BatchHost=nia0739
   NumNodes=4 NumCPUs=320 NumTasks=4 CPUs/Task=8 ReqB:S:C:T=0:0:*:*
   TRES=cpu=320,mem=700000M,node=4,billing=160
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=8 MinMemoryNode=175000M MinTmpDiskNode=0
   Features=[skylake|cascade] DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/fs0/scratch/p/primath/maxzhang/distributed-network-layout/BatchScript.sh
   WorkDir=/gpfs/fs0/scratch/p/primath/maxzhang/distributed-network-layout
   Comment=/opt/slurm/bin/sbatch --export=NONE BatchScript.sh 
   StdErr=/gpfs/fs0/scratch/p/primath/maxzhang/distributed-network-layout/jobOutput/DistributedLayoutAlgorithm_output_7615933.txt
   StdIn=/dev/null
   StdOut=/gpfs/fs0/scratch/p/primath/maxzhang/distributed-network-layout/jobOutput/DistributedLayoutAlgorithm_output_7615933.txt
   Power=
   MailUser=maxjingwei.zhang@ryerson.ca MailType=BEGIN,END,FAIL
   

sacct -j 7615933
JobID           JobName    Account    Elapsed  MaxVMSize     MaxRSS  SystemCPU    UserCPU ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- ---------- ---------- -------- 
7615933      Distribut+ rrg-prima+   00:15:47                        00:05.380  00:39.662      0:0 
7615933.bat+      batch rrg-prima+   00:15:47    860928K     16168K  00:00.856  00:00.929      0:0 
7615933.ext+     extern rrg-prima+   00:15:52    142384K      1132K   00:00:00  00:00.002      0:0 
7615933.0    spark-sub+ rrg-prima+   00:15:17 115517472K    421904K  00:03.806  00:38.264      1:0 
7615933.1    start-sla+ rrg-prima+   00:15:22  14622440K    430740K  00:00.716  00:00.466      0:9 
