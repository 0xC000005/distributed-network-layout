
Due to MODULEPATH changes, the following have been reloaded:
  1) mii/1.1.1


The following have been reloaded with a version change:
  1) python/3.7.4 => python/3.6.3

starting org.apache.spark.deploy.master.Master, logging to /home/p/primath/maxzhang/.spark/2.4.4/log/spark-7616075-org.apache.spark.deploy.master.Master-1-nia0294.scinet.local.out
Master URL = spark://nia0294:7077
Number of Workers = 3
https://repos.spark-packages.org added as a remote repository with the name: repo-1
Ivy Default Cache set to: /home/p/primath/maxzhang/.ivy2/cache
The jars for the packages stored in: /home/p/primath/maxzhang/.ivy2/jars
:: loading settings :: url = jar:file:/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/spark/2.4.4/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
graphframes#graphframes added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-5b1e5db6-b2a5-4f3d-ab22-501322ce47ff;1.0
	confs: [default]
	found graphframes#graphframes;0.8.0-spark2.4-s_2.11 in local-m2-cache
downloading file:/home/p/primath/maxzhang/.m2/repository/graphframes/graphframes/0.8.0-spark2.4-s_2.11/graphframes-0.8.0-spark2.4-s_2.11.jar ...
	[SUCCESSFUL ] graphframes#graphframes;0.8.0-spark2.4-s_2.11!graphframes.jar (32ms)
:: resolution report :: resolve 765531ms :: artifacts dl 35ms
	:: modules in use:
	graphframes#graphframes;0.8.0-spark2.4-s_2.11 from local-m2-cache in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   1   |   1   |   0   |   0   ||   1   |   1   |
	---------------------------------------------------------------------

:: problems summary ::
:::: ERRORS
	Server access error at url https://repo1.maven.org/maven2/graphframes/graphframes/0.8.0-spark2.4-s_2.11/graphframes-0.8.0-spark2.4-s_2.11.pom (java.net.ConnectException: Connection timed out (Connection timed out))

	Server access error at url https://repo1.maven.org/maven2/graphframes/graphframes/0.8.0-spark2.4-s_2.11/graphframes-0.8.0-spark2.4-s_2.11.jar (java.net.ConnectException: Connection timed out (Connection timed out))

	Server access error at url https://dl.bintray.com/spark-packages/maven/graphframes/graphframes/0.8.0-spark2.4-s_2.11/graphframes-0.8.0-spark2.4-s_2.11.pom (java.net.ConnectException: Connection timed out (Connection timed out))

	Server access error at url https://dl.bintray.com/spark-packages/maven/graphframes/graphframes/0.8.0-spark2.4-s_2.11/graphframes-0.8.0-spark2.4-s_2.11.jar (java.net.ConnectException: Connection timed out (Connection timed out))

	Server access error at url https://repos.spark-packages.org/graphframes/graphframes/0.8.0-spark2.4-s_2.11/graphframes-0.8.0-spark2.4-s_2.11.pom (java.net.ConnectException: Connection timed out (Connection timed out))

	Server access error at url https://repos.spark-packages.org/graphframes/graphframes/0.8.0-spark2.4-s_2.11/graphframes-0.8.0-spark2.4-s_2.11.jar (java.net.ConnectException: Connection timed out (Connection timed out))


:: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS
:: retrieving :: org.apache.spark#spark-submit-parent-5b1e5db6-b2a5-4f3d-ab22-501322ce47ff
	confs: [default]
	1 artifacts copied, 0 already retrieved (371kB/18ms)
22/06/28 16:29:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/scipy-stack/2019a/lib/python3.6/site-packages/matplotlib/font_manager.py:232: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.
  'Matplotlib is building the font cache using fc-list. '
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/06/28 16:31:20 INFO SparkContext: Running Spark version 2.4.4
22/06/28 16:31:20 INFO SparkContext: Submitted application: covid19vaccine_twitter_replyto_net_feb2021
22/06/28 16:31:20 INFO SecurityManager: Changing view acls to: maxzhang
22/06/28 16:31:20 INFO SecurityManager: Changing modify acls to: maxzhang
22/06/28 16:31:20 INFO SecurityManager: Changing view acls groups to: 
22/06/28 16:31:20 INFO SecurityManager: Changing modify acls groups to: 
22/06/28 16:31:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(maxzhang); groups with view permissions: Set(); users  with modify permissions: Set(maxzhang); groups with modify permissions: Set()
22/06/28 16:31:20 INFO Utils: Successfully started service 'sparkDriver' on port 35402.
22/06/28 16:31:20 INFO SparkEnv: Registering MapOutputTracker
22/06/28 16:31:20 INFO SparkEnv: Registering BlockManagerMaster
22/06/28 16:31:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/06/28 16:31:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/06/28 16:31:20 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-3fd5e0f7-3104-4651-b055-a4ba8231140d
22/06/28 16:31:20 INFO MemoryStore: MemoryStore started with capacity 53.2 GB
22/06/28 16:31:20 INFO SparkEnv: Registering OutputCommitCoordinator
22/06/28 16:31:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
22/06/28 16:31:20 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://nia0294:4040
22/06/28 16:31:20 INFO SparkContext: Added JAR file:///home/p/primath/maxzhang/.ivy2/jars/graphframes_graphframes-0.8.0-spark2.4-s_2.11.jar at spark://nia0294:35402/jars/graphframes_graphframes-0.8.0-spark2.4-s_2.11.jar with timestamp 1656448280937
22/06/28 16:31:20 INFO SparkContext: Added file file:///home/p/primath/maxzhang/.ivy2/jars/graphframes_graphframes-0.8.0-spark2.4-s_2.11.jar at spark://nia0294:35402/files/graphframes_graphframes-0.8.0-spark2.4-s_2.11.jar with timestamp 1656448280953
22/06/28 16:31:20 INFO Utils: Copying /home/p/primath/maxzhang/.ivy2/jars/graphframes_graphframes-0.8.0-spark2.4-s_2.11.jar to /tmp/spark-7167776f-160c-47c9-b014-f27e51ea4a68/userFiles-e5e1755e-ca98-4253-b8ef-c5c84481230a/graphframes_graphframes-0.8.0-spark2.4-s_2.11.jar
22/06/28 16:31:21 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://nia0294:7077...
22/06/28 16:31:21 INFO TransportClientFactory: Successfully created connection to nia0294/10.20.5.6:7077 after 28 ms (0 ms spent in bootstraps)
22/06/28 16:31:21 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20220628163121-0000
22/06/28 16:31:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36001.
22/06/28 16:31:21 INFO NettyBlockTransferService: Server created on nia0294:36001
22/06/28 16:31:21 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/06/28 16:31:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20220628163121-0000/0 on worker-20220628161654-10.20.6.49-37108 (10.20.6.49:37108) with 5 core(s)
22/06/28 16:31:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20220628163121-0000/0 on hostPort 10.20.6.49:37108 with 5 core(s), 16.0 GB RAM
22/06/28 16:31:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20220628163121-0000/1 on worker-20220628161654-10.20.13.38-37667 (10.20.13.38:37667) with 5 core(s)
22/06/28 16:31:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20220628163121-0000/1 on hostPort 10.20.13.38:37667 with 5 core(s), 16.0 GB RAM
22/06/28 16:31:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20220628163121-0000/2 on worker-20220628161654-10.20.6.49-36248 (10.20.6.49:36248) with 5 core(s)
22/06/28 16:31:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20220628163121-0000/2 on hostPort 10.20.6.49:36248 with 5 core(s), 16.0 GB RAM
22/06/28 16:31:21 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20220628163121-0000/3 on worker-20220628161654-10.20.13.32-45263 (10.20.13.32:45263) with 5 core(s)
22/06/28 16:31:21 INFO StandaloneSchedulerBackend: Granted executor ID app-20220628163121-0000/3 on hostPort 10.20.13.32:45263 with 5 core(s), 16.0 GB RAM
22/06/28 16:31:21 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, nia0294, 36001, None)
22/06/28 16:31:21 INFO BlockManagerMasterEndpoint: Registering block manager nia0294:36001 with 53.2 GB RAM, BlockManagerId(driver, nia0294, 36001, None)
22/06/28 16:31:21 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, nia0294, 36001, None)
22/06/28 16:31:21 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, nia0294, 36001, None)
22/06/28 16:31:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20220628163121-0000/2 is now RUNNING
22/06/28 16:31:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20220628163121-0000/0 is now RUNNING
22/06/28 16:31:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20220628163121-0000/3 is now RUNNING
22/06/28 16:31:21 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20220628163121-0000/1 is now RUNNING
22/06/28 16:31:21 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
22/06/28 16:31:22 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/gpfs/fs0/scratch/p/primath/maxzhang/distributed-network-layout/spark-warehouse').
22/06/28 16:31:22 INFO SharedState: Warehouse path is 'file:/gpfs/fs0/scratch/p/primath/maxzhang/distributed-network-layout/spark-warehouse'.
22/06/28 16:31:22 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
Checkpoint directory already exist
Num of nodes: 25944
Num of edges: 18065
0 Iterations are completed
1 Iterations are completed
2 Iterations are completed
3 Iterations are completed
4 Iterations are completed
5 Iterations are completed
6 Iterations are completed
7 Iterations are completed
8 Iterations are completed
9 Iterations are completed
10 Iterations are completed
11 Iterations are completed
12 Iterations are completed
13 Iterations are completed
14 Iterations are completed
15 Iterations are completed
16 Iterations are completed
17 Iterations are completed
18 Iterations are completed
19 Iterations are completed
20 Iterations are completed
21 Iterations are completed
22 Iterations are completed
23 Iterations are completed
24 Iterations are completed
25 Iterations are completed
26 Iterations are completed
27 Iterations are completed
28 Iterations are completed
29 Iterations are completed
30 Iterations are completed
31 Iterations are completed
32 Iterations are completed
33 Iterations are completed
34 Iterations are completed
35 Iterations are completed
36 Iterations are completed
37 Iterations are completed
38 Iterations are completed
39 Iterations are completed
40 Iterations are completed
41 Iterations are completed
42 Iterations are completed
43 Iterations are completed
44 Iterations are completed
45 Iterations are completed
46 Iterations are completed
47 Iterations are completed
48 Iterations are completed
49 Iterations are completed
time taken for layout of combined levels = 2090.246535997954
list of nodes are collected
list of nodes positions are collected
list of nodes degree are collected
dict of nodes and their positions are created
networkx graph object is created
/cvmfs/soft.computecanada.ca/easybuild/software/2017/Core/networkx/1.1/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py:611: MatplotlibDeprecationWarning: isinstance(..., numbers.Number)
  if cb.is_numlike(alpha):
networkx graph using distribute layout is created
graph is saved to the disk
Num of nodes: 25944
Num of edges: 18065
Nodes and Edges dataframes saved to disk
Successfully deleted the directory sampleOutput1checkpoint 
srun: forcing job termination
stopping org.apache.spark.deploy.master.Master

scontrol show jobid 7616075
JobId=7616075 JobName=DistributedLayoutAlgorithm
   UserId=maxzhang(3119754) GroupId=primath(6038442) MCS_label=N/A
   Priority=2379415 Nice=0 Account=rrg-primath QOS=normal
   JobState=COMPLETING Reason=None Dependency=(null)
   Requeue=0 Restarts=0 BatchFlag=1 Reboot=0 ExitCode=0:0
   RunTime=00:52:59 TimeLimit=1-00:00:00 TimeMin=N/A
   SubmitTime=2022-06-28T16:12:59 EligibleTime=2022-06-28T16:12:59
   AccrueTime=2022-06-28T16:12:59
   StartTime=2022-06-28T16:15:58 EndTime=2022-06-28T17:08:57 Deadline=N/A
   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2022-06-28T16:15:58 Scheduler=Main
   Partition=compute AllocNode:Sid=nia-login03:61617
   ReqNodeList=(null) ExcNodeList=(null)
   NodeList=nia[0409,0896,0902]
   BatchHost=nia0294
   NumNodes=3 NumCPUs=320 NumTasks=4 CPUs/Task=8 ReqB:S:C:T=0:0:*:*
   TRES=cpu=320,mem=700000M,node=4,billing=160
   Socks/Node=* NtasksPerN:B:S:C=1:0:*:* CoreSpec=*
   MinCPUsNode=8 MinMemoryNode=175000M MinTmpDiskNode=0
   Features=[skylake|cascade] DelayBoot=00:00:00
   OverSubscribe=NO Contiguous=0 Licenses=(null) Network=(null)
   Command=/gpfs/fs0/scratch/p/primath/maxzhang/distributed-network-layout/BatchScript.sh
   WorkDir=/gpfs/fs0/scratch/p/primath/maxzhang/distributed-network-layout
   Comment=/opt/slurm/bin/sbatch --export=NONE BatchScript.sh 
   StdErr=/gpfs/fs0/scratch/p/primath/maxzhang/distributed-network-layout/jobOutput/DistributedLayoutAlgorithm_output_7616075.txt
   StdIn=/dev/null
   StdOut=/gpfs/fs0/scratch/p/primath/maxzhang/distributed-network-layout/jobOutput/DistributedLayoutAlgorithm_output_7616075.txt
   Power=
   MailUser=maxjingwei.zhang@ryerson.ca MailType=BEGIN,END,FAIL
   

sacct -j 7616075
JobID           JobName    Account    Elapsed  MaxVMSize     MaxRSS  SystemCPU    UserCPU ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- ---------- ---------- -------- 
7616075      Distribut+ rrg-prima+   00:52:59                        01:43.217  08:02.508      0:0 
7616075.bat+      batch rrg-prima+   00:52:59    860976K     16164K  00:00.867  00:00.901      0:0 
7616075.ext+     extern rrg-prima+   00:52:59    142384K      1132K  00:00.002  00:00.001      0:0 
7616075.0    spark-sub+ rrg-prima+   00:52:36 138333440K   7567388K  01:42.348  08:01.605      0:0 
7616075.1    start-sla+ rrg-prima+   00:52:36                         00:00:00   00:00:00      0:0 
